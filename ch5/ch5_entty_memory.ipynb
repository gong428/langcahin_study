{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConversationEntityMemory\n",
    "대화 내용에서 엔티티 정보를 추출하고 저장하는 메모리 클래스입니다\n",
    "- ConversationEntityMemory는 대화 내용을 저장하면서 동시에 엔티티 정보를 추출하여 별도로 관리합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationEntityMemory\n",
    "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant to a human, powered by a large language model trained by OpenAI.\n",
      "\n",
      "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
      "\n",
      "Context:\n",
      "{entities}\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Last line:\n",
      "Human: {input}\n",
      "You:\n"
     ]
    }
   ],
   "source": [
    "# Entity Memory를 사용하는 프롬프트 내용을 출력합니다.\n",
    "print(ENTITY_MEMORY_CONVERSATION_TEMPLATE.template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\",\n",
    "                 temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
    "    memory=ConversationEntityMemory(llm=llm)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'그렇군요! gong과 gang이 lagngchain을 공부하고 블로그를 운영하는 것은 정말 흥미로운 일입니다. 그들이 어떤 주제에 대해 논문을 리뷰하고 있는지, 또는 어떤 최신 AI 기술 동향에 관심이 있는지 궁금하네요. 혹시 그들의 블로그에 대해 더 이야기해 줄 수 있나요?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(\n",
    "    input=\"gong와 gang는 한 학교에서 공부하는 학우입니다.\"\n",
    "    \"gong과 gang은 lagngchain을 공부하는 주니어 개발자입니다.. \"\n",
    "    \"그들은 블로그를 운영하면서 논문을 리뷰하고 최신 ai 기술 동향을 파악하려고 노력하고 있습니다.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gong': 'gong는 한 학교에서 공부하는 학우이며, lagngchain을 공부하는 주니어 개발자로 블로그를 운영하고 논문을 리뷰하고 최신 AI 기술 동향을 파악하려고 노력하고 있습니다.',\n",
       " 'gang': 'gang은 gong와 함께 한 학교에서 공부하는 학우이며, lagngchain을 공부하는 주니어 개발자입니다. 그들은 블로그를 운영하면서 논문을 리뷰하고 최신 AI 기술 동향을 파악하려고 노력하고 있습니다.',\n",
       " 'lagngchain': 'gong과 gang은 lagngchain을 공부하는 주니어 개발자입니다.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# entity memory 를 출력합니다.\n",
    "conversation.memory.entity_store.store\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConversationKGMemory\n",
    "\n",
    "대화 내용을 지식 그래프 형태로 저장하고 관리하는 메모리 클래스입니다\n",
    "\n",
    "ConversationKGMemory는 대화 내용에서 엔티티와 관계를 추출하여 지식 그래프를 구축합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationKGMemory\n",
    "##지식 그래프의 힘을 활용하여 정보를 저장하고 불러옵니다.\n",
    "\n",
    "##이를 통해 모델이 서로 다른 개체 간의 관계를 이해하는 데 도움을 주고, 복잡한 연결망과 역사적 맥락을 기반으로 대응하는 능력을 향상시킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "memory = ConversationKGMemory(llm=llm, return_messages=True)\n",
    "memory.save_context(\n",
    "    {\"input\": \"이쪽은 Gumi 에 거주중인 김강우씨 입니다.\"},\n",
    "    {\"output\": \"김강우씨는 누구시죠?\"},\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\": \"김강우씨는 우리 학교의 langchain 주니어 개발자입니다.\"},\n",
    "    {\"output\": \"만나서 반갑습니다.\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='On 김강우씨: 김강우씨 is a langchain junior developer. 김강우씨 is at our school.', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({\"input\": \"김강우씨는 누구입니까?\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"The following is a friendly conversation between a human and an AI. \n",
    "The AI is talkative and provides lots of specific details from its context. \n",
    "If the AI does not know the answer to a question, it truthfully says it does not know. \n",
    "The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
    "\n",
    "Relevant Information:\n",
    "\n",
    "{history}\n",
    "\n",
    "Conversation:\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"input\"], template=template)\n",
    "\n",
    "conversation_with_kg = ConversationChain(\n",
    "    llm=llm, prompt=prompt, memory=ConversationKGMemory(llm=llm)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Teddy! It's great to meet you. How exciting that Shirley is a new designer at your company! What kind of design work does she do? Is she focusing on graphic design, product design, or something else?\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_kg.predict(\n",
    "    input=\"My name is Teddy. Shirley is a coworker of mine, and she's a new designer at our company.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'On Shirley: Shirley is a coworker. Shirley is a new designer. Shirley works at the company.'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shirley 에 대한 질문\n",
    "conversation_with_kg.memory.load_memory_variables({\"input\": \"who is Shirley?\"})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lanchain_study311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
